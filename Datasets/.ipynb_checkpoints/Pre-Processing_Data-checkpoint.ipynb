{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7e185ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import html\n",
    "from langdetect import detect\n",
    "\n",
    "import contractions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "942ad9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1b653e",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "- Removing Emotions\n",
    "- Removing URLs\n",
    "- Removing unicode Characters\n",
    "- Removing hashtag and mentions\n",
    "- Remvoing contractions and **stopwords**\n",
    "- Removing special characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6106228e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emojis(text):\n",
    "    # Remove emojis\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\" \n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text)\n",
    "    filtered_text = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_text)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert HTML entities back to their original characters\n",
    "    text = html.unescape(text)\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    text=contractions.fix(text)\n",
    "    \n",
    "    # Remove unicode characters\n",
    "    text = text.encode('ascii', 'ignore').decode('ascii')\n",
    "\n",
    "    # Remove mentions (@username)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "\n",
    "    # Remove hashtags (#topic)\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "    \n",
    "    #remove special Characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # Remove emojis\n",
    "    text = remove_emojis(text)\n",
    "\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    text = ' '.join(word for word in text.split() if not word.startswith('pictwittercom'))\n",
    "\n",
    "    text=remove_stopwords(text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe27e39",
   "metadata": {},
   "source": [
    "## Considering only English texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "819904eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == 'en'\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2324500",
   "metadata": {},
   "source": [
    "## Balancing Number of rows belonging to each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad9f73b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def balance_dataframe(df, binary_column, text_column):\n",
    "    # Step 1: Separate the DataFrame based on binary_column values\n",
    "    df_0 = df[df[binary_column] == 0]\n",
    "    df_1 = df[df[binary_column] == 1]\n",
    "\n",
    "    # Step 2: Sort both DataFrames based on the length of text_column in descending order\n",
    "    df_0 = df_0.assign(text_length=df_0[text_column].str.len())\n",
    "    df_1 = df_1.assign(text_length=df_1[text_column].str.len())\n",
    "    df_0 = df_0.sort_values(by='text_length', ascending=False)\n",
    "    df_1 = df_1.sort_values(by='text_length', ascending=False)\n",
    "\n",
    "    # Step 3: Determine which value has more occurrences\n",
    "    num_0 = df_0.shape[0]\n",
    "    num_1 = df_1.shape[0]\n",
    "    if num_0 > num_1:\n",
    "        # Step 4: Slice the larger DataFrame to match the number of occurrences of the less frequent value\n",
    "        df_0 = df_0.iloc[:num_1]\n",
    "    else:\n",
    "        df_1 = df_1.iloc[:num_0]\n",
    "\n",
    "    # Step 5: Concatenate the DataFrames back together\n",
    "    df_balanced = pd.concat([df_0, df_1], ignore_index=True)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    df_balanced = df_balanced.drop(['text_length', text_column], axis=1)\n",
    "\n",
    "    return df_balanced\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dab1776",
   "metadata": {},
   "source": [
    "## Function For triggering pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1b3493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_balance_dataframe(df):\n",
    "    # Preprocess the text in 'message' column and create 'cleaned_text' column\n",
    "    df['cleaned_text'] = df['message'].apply(preprocess_text)\n",
    "\n",
    "    # Filter rows where 'cleaned_text' is in English\n",
    "    df = df[df['cleaned_text'].apply(is_english)]\n",
    "\n",
    "    # Reset the index of the DataFrame\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # Balance the DataFrame based on 'label' column and 'message' column\n",
    "    df = balance_dataframe(df, 'label', 'message')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd73d1c",
   "metadata": {},
   "source": [
    "## Running for all three datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e27cc789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    8000\n",
      "1    2314\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "0    1948\n",
      "1    1948\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>men follow men nobody tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>bought mh bundle create task called mario star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>brand business putting logo products services ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>assumes taboo start email lol considering repl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>great stuff thanks 4 add bounce done roll cheers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3891</th>\n",
       "      <td>1</td>\n",
       "      <td>wow love depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3892</th>\n",
       "      <td>1</td>\n",
       "      <td>depression wanima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3893</th>\n",
       "      <td>1</td>\n",
       "      <td>depression came back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3894</th>\n",
       "      <td>1</td>\n",
       "      <td>depression 0beck 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3895</th>\n",
       "      <td>1</td>\n",
       "      <td>perspective</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3896 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                       cleaned_text\n",
       "0         0                       men follow men nobody tweets\n",
       "1         0  bought mh bundle create task called mario star...\n",
       "2         0  brand business putting logo products services ...\n",
       "3         0  assumes taboo start email lol considering repl...\n",
       "4         0   great stuff thanks 4 add bounce done roll cheers\n",
       "...     ...                                                ...\n",
       "3891      1                                wow love depression\n",
       "3892      1                                  depression wanima\n",
       "3893      1                               depression came back\n",
       "3894      1                                 depression 0beck 1\n",
       "3895      1                                        perspective\n",
       "\n",
       "[3896 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.read_csv('sentiment_tweets3.csv')\n",
    "print(df1['label'].value_counts())\n",
    "df1=df1.drop('Unnamed: 0',axis=1)\n",
    "df1=preprocess_and_balance_dataframe(df1)\n",
    "print(df1['label'].value_counts())\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ab59f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    2357\n",
      "1     843\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "0    679\n",
      "1    679\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>feeling depressed know alone know see hear sup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>erosion soul caused people positions power liv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>depression may carry feeling worthlessness fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>going keep banging cos true focus get stop tel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>going keep banging cos true focus get stop tel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>1</td>\n",
       "      <td>working new years eve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>1</td>\n",
       "      <td>forgot cheese cake work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>1</td>\n",
       "      <td>one sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>1</td>\n",
       "      <td>god please help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>1</td>\n",
       "      <td>creeps</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1358 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                       cleaned_text\n",
       "0         0  feeling depressed know alone know see hear sup...\n",
       "1         0  erosion soul caused people positions power liv...\n",
       "2         0  depression may carry feeling worthlessness fee...\n",
       "3         0  going keep banging cos true focus get stop tel...\n",
       "4         0  going keep banging cos true focus get stop tel...\n",
       "...     ...                                                ...\n",
       "1353      1                              working new years eve\n",
       "1354      1                            forgot cheese cake work\n",
       "1355      1                                            one sec\n",
       "1356      1                                    god please help\n",
       "1357      1                                             creeps\n",
       "\n",
       "[1358 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=pd.read_csv('tweets_combined.csv')\n",
    "print(df2['target'].value_counts())\n",
    "df2=df2.drop('Unnamed: 0',axis=1)\n",
    "df2.columns=['message','label']\n",
    "df2=preprocess_and_balance_dataframe(df2)\n",
    "print(df2['label'].value_counts())\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fdc025a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    1268\n",
      "0     783\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "0    768\n",
      "1    768\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>812th done wow canny believe cracking morning ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>thrilled opportunity talk mentalhealth nftart ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>manifestationmonday favorite thing mondays lau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>orange heart dog face happy international dog ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>good morning paris tokyo tower thermometer ast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>1</td>\n",
       "      <td>many would like see mentalhealth elements heal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>1</td>\n",
       "      <td>generalised anxiety disorder include worry mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>1</td>\n",
       "      <td>loss hormone allopregnanolone linked altered b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>1</td>\n",
       "      <td>commitments asks candidates ratio one social w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>1</td>\n",
       "      <td>loss hormone allopregnanolone linked altered b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1536 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                       cleaned_text\n",
       "0         0  812th done wow canny believe cracking morning ...\n",
       "1         0  thrilled opportunity talk mentalhealth nftart ...\n",
       "2         0  manifestationmonday favorite thing mondays lau...\n",
       "3         0  orange heart dog face happy international dog ...\n",
       "4         0  good morning paris tokyo tower thermometer ast...\n",
       "...     ...                                                ...\n",
       "1531      1  many would like see mentalhealth elements heal...\n",
       "1532      1  generalised anxiety disorder include worry mon...\n",
       "1533      1  loss hormone allopregnanolone linked altered b...\n",
       "1534      1  commitments asks candidates ratio one social w...\n",
       "1535      1  loss hormone allopregnanolone linked altered b...\n",
       "\n",
       "[1536 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3=pd.read_excel('Twitter_Non-Advert.xlsx')\n",
    "print(df3['label'].value_counts())\n",
    "df3.columns=['message','label']\n",
    "df3=preprocess_and_balance_dataframe(df3)\n",
    "print(df3['label'].value_counts())\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c0fae2",
   "metadata": {},
   "source": [
    "## Saving the combines results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61c811d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    3395\n",
      "1    3395\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "0    3313\n",
      "1    3275\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "result_concat_row = pd.concat([df1, df2, df3], axis=0)\n",
    "print(result_concat_row['label'].value_counts())\n",
    "\n",
    "result_concat_row=result_concat_row.drop_duplicates()\n",
    "print(result_concat_row['label'].value_counts())\n",
    "\n",
    "result_concat_row.to_csv('Cleaned_Tweets.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
